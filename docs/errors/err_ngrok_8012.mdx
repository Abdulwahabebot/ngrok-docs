import streamlit as st
from langchain.chains.qa_with_sources import load_qa_with_sources_chain # Use the correct import for load_qa_chain
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from pprint import pprint



# Function to load and process PDF
def process_pdf(pdf_file):
    pdf_loader = PyPDFLoader(pdf_file)
    pages = pdf_loader.load_and_split()
    return pages

# Function to generate answer using LangChain
def generate_answer(pages, question):
    # Assuming 'model' is defined somewhere, otherwise you need to initialize it here
    context = "\n".join(str(p.page_content) for p in pages[:30])
    prompt_template = """Answer the question as precise as possible using the provided context. If the answer is
                        not contained in the context, say "answer not available in context" \n\n
                        Context: \n {context}?\n
                        Question: \n {question} \n
                        Answer:\n"""
    prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
    # Update the function call to use load_qa_with_sources_chain
    stuff_chain = load_qa_with_sources_chain(model, chain_type="stuff", prompt=prompt)
    stuff_answer = stuff_chain({"input_documents": pages[10:13], "question": question}, return_only_outputs=True)
    return stuff_answer

# Streamlit UI
st.title('Document QA App')
uploaded_file = st.file_uploader("/content/cambridge-igcse-computer-science.pdf", type="pdf")

if uploaded_file is not None:
    pages = process_pdf(uploaded_file)
    st.write("PDF loaded successfully!")

    question = st.text_input("Enter your question:")
    if st.button("Get Answer"):
        if question:
            answer = generate_answer(pages, question)
            st.write(answer)
        else:
            st.write("Please enter a question.")
